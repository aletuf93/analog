<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>analogistics.stat_time_series API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>analogistics.stat_time_series</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># %% import packages

import numpy as np
import pandas as pd
import itertools
import warnings
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from matplotlib.colors import Normalize

from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.tsa.stattools import adfuller
import statsmodels.api as sm

from pandas.api.types import CategoricalDtype

from scipy.stats import boxcox


def timeStampToDays(series: pd.Series) -&gt; pd.Series:
    &#34;&#34;&#34;
    Convert a datetime series into float series with the number of days
    :param series: DESCRIPTION input pandas series
    :type series: pd.Series
    :return: DESCRIPTION pandas series with float of days
    :rtype: TYPE pd.Series

    &#34;&#34;&#34;

    D = series.dt.components[&#39;days&#39;]
    H = series.dt.components[&#39;hours&#39;]
    M = series.dt.components[&#39;minutes&#39;]
    result = D + (H / 24) + (M / (60 * 24))
    return result


def sampleTimeSeries(series: pd.Series,
                     sampleInterval: str) -&gt; pd.Series:
    &#34;&#34;&#34;
    Sample a pandas series using a sampling interval
    :param series: DESCRIPTION input pandas datetime series
    :type series: pd.Series
    :param sampleInterval: DESCRIPTION type of sampling required
    :type sampleInterval: str
    :raises ValueError: DESCRIPTION error in case of invalid sampling parameter
    :return: DESCRIPTION Output sampled seried
    :rtype: TYPE pd.Series

    &#34;&#34;&#34;

    if sampleInterval not in [&#39;day&#39;, &#39;week&#39;, &#39;month&#39;, &#39;year&#39;]:
        raise ValueError(f&#34;&#34;&#34;sampleInterval parameter: {sampleInterval} not a valid sample interval.
                          Choose between [&#39;day&#39;, &#39;week&#39;, &#39;month&#39;, &#39;year&#39;]&#34;&#34;&#34;)
    if sampleInterval == &#39;day&#39;:
        series = series.dt.strftime(&#39;%Y-%j&#39;)
    elif sampleInterval == &#39;week&#39;:
        series = series.dt.strftime(&#39;%Y-%U&#39;)
    elif sampleInterval == &#39;month&#39;:
        series = series.dt.strftime(&#39;%Y-%m&#39;)
    elif sampleInterval == &#39;year&#39;:
        series = series.dt.strftime(&#39;%Y&#39;)
    return series


def groupPerWeek(df: pd.DataFrame,
                 timeVariable: str,
                 groupVariable: str,
                 groupType: str) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Perform a weekly groupby based on a datetime variable, applying a specific type of grouping
    :param df: DESCRIPTION input pandas dataframe
    :type df: pd.DataFrame
    :param timeVariable: DESCRIPTION column name corresponding to the time variable
    :type timeVariable: str
    :param groupVariable: DESCRIPTION column name corresponding to the grouping variable
    :type groupVariable: str
    :param groupType: DESCRIPTION type of grouping function
    :type groupType: str
    :return: DESCRIPTION Output grouped DataFrame
    :rtype: TYPE pd.DataFrame

    &#34;&#34;&#34;

    if groupType not in [&#39;count&#39;, &#39;sum&#39;]:
        raise ValueError(f&#34;&#34;&#34;groupType parameter: {groupType} not a valid grouping function.
                          Choose between [&#39;count&#39;, &#39;sum&#39;]&#34;&#34;&#34;)

    # convert to dataframe if a series
    if isinstance(df, pd.Series):
        df = pd.DataFrame([[df.index.values.T, df.values]],
                          columns=[timeVariable, groupVariable])

    df[&#39;DatePeriod&#39;] = pd.to_datetime(df[timeVariable]) - pd.to_timedelta(7, unit=&#39;d&#39;)

    if groupType == &#39;count&#39;:
        df = df.groupby([pd.Grouper(key=timeVariable,
                                    freq=&#39;W-MON&#39;)])[groupVariable].size()
    elif groupType == &#39;sum&#39;:
        df = df.groupby([pd.Grouper(key=timeVariable,
                                    freq=&#39;W-MON&#39;)])[groupVariable].sum()
    df = df.sort_index()
    return df


def groupPerMonth(df: pd.DataFrame,
                  timeVariable: str,
                  groupVariable: str,
                  groupType: str) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Perform a monthly groupby based on a datetime variable, applying a specific type of grouping
    :param df: DESCRIPTION input pandas dataframe
    :type df: pd.DataFrame
    :param timeVariable: DESCRIPTION column name corresponding to the time variable
    :type timeVariable: str
    :param groupVariable: DESCRIPTION column name corresponding to the grouping variable
    :type groupVariable: str
    :param groupType: DESCRIPTION type of grouping function
    :type groupType: str
    :return: DESCRIPTION Output grouped DataFrame
    :rtype: TYPE pd.DataFrame

    &#34;&#34;&#34;

    if groupType not in [&#39;count&#39;, &#39;sum&#39;]:
        raise ValueError(f&#34;&#34;&#34;groupType parameter: {groupType} not a valid grouping function.
                          Choose between [&#39;count&#39;, &#39;sum&#39;]&#34;&#34;&#34;)

    if isinstance(df, pd.Series):  # convert to dataframe if a series
        df = pd.DataFrame([[df.index.values.T, df.values]],
                          columns=[timeVariable, groupVariable])

    # df[&#39;DatePeriod&#39;] = pd.to_datetime(df[timeVariable]) - pd.to_timedelta(7, unit=&#39;d&#39;)

    if groupType == &#39;count&#39;:
        df = df.groupby([pd.Grouper(key=timeVariable, freq=&#39;M&#39;)])[groupVariable].size()
    elif groupType == &#39;sum&#39;:
        df = df.groupby([pd.Grouper(key=timeVariable, freq=&#39;M&#39;)])[groupVariable].sum()
    df = df.sort_index()
    return df


def groupPerWeekday(df: pd.DataFrame,
                    timeVariable: str,
                    groupVariable: str) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Perform a groupby per weekday based on a datetime variable, applying a specific type of grouping
    :param df: DESCRIPTION input pandas dataframe
    :type df: pd.DataFrame
    :param timeVariable: DESCRIPTION column name corresponding to the time variable
    :type timeVariable: str
    :param groupVariable: DESCRIPTION column name corresponding to the grouping variable
    :type groupVariable: str
    :return: DESCRIPTION Output grouped DataFrame
    :rtype: TYPE pd.DataFrame

    &#34;&#34;&#34;

    cats = [&#39;Monday&#39;, &#39;Tuesday&#39;, &#39;Wednesday&#39;, &#39;Thursday&#39;, &#39;Friday&#39;, &#39;Saturday&#39;, &#39;Sunday&#39;]
    cat_type = CategoricalDtype(categories=cats, ordered=True)

    df[&#39;Weekday&#39;] = df[timeVariable].dt.day_name()
    df[&#39;Weekday&#39;] = df[&#39;Weekday&#39;].astype(cat_type)
    D_grouped = df.groupby([&#39;Weekday&#39;]).agg({groupVariable: [&#39;size&#39;, &#39;mean&#39;, &#39;std&#39;]})
    D_grouped.columns = D_grouped.columns.droplevel(0)
    D_grouped[&#39;mean&#39;] = np.round(D_grouped[&#39;mean&#39;], 2)
    D_grouped[&#39;std&#39;] = np.round(D_grouped[&#39;std&#39;], 2)
    return D_grouped


def assignWeekDay(df: pd.DataFrame,
                  timeVariable: str) -&gt; tuple:
    &#34;&#34;&#34;
    Return the day of the week, and a boolean indicating whether the day is in the weekend
    :param df: DESCRIPTION input pandas dataframe
    :type df: pd.DataFrame
    :param timeVariable: DESCRIPTION column name corresponding to the time variable
    :type timeVariable: str
    :return: DESCRIPTION tuple with the day of the week, and a boolean for weekend
    :rtype: tuple

    &#34;&#34;&#34;
    dayOfTheWeek = df[timeVariable].dt.weekday_name
    weekend = (dayOfTheWeek == &#39;Sunday&#39;) | (dayOfTheWeek == &#39;Saturday&#39;)
    weekEnd = weekend.copy()
    weekEnd[weekend] = &#39;Weekend&#39;
    weekEnd[~weekend] = &#39;Weekday&#39;
    return dayOfTheWeek, weekEnd


def ACF_PACF_plot(series: pd.Series) -&gt; tuple:
    &#34;&#34;&#34;
    Creates a graph with a time series, the ACF and the PACF. In addition, it returns
    two pandas Series with the significant lags in the ACF and PACF
    :param series: DESCRIPTION input pandas series with the observations
    :type series: pd.Series
    :return: DESCRIPTION output tuple
    :rtype: tuple

    &#34;&#34;&#34;

    # Prepare the output figure
    fig = plt.subplot(131)

    plt.plot(series, &#39;skyblue&#39;)
    plt.xticks(rotation=30)
    plt.title(&#39;Time Series&#39;)

    lag_acf = acf(series, nlags=20)
    lag_pacf = pacf(series, nlags=20)

    plt.subplot(132)
    plt.stem(lag_acf, linefmt=&#39;skyblue&#39;, markerfmt=&#39;d&#39;)
    plt.axhline(y=0, linestyle=&#39;--&#39;)
    plt.axhline(y=-1.96 / np.sqrt(len(series)), linestyle=&#39;--&#39;, color=&#39;r&#39;)
    plt.axhline(y=1.96 / np.sqrt(len(series)), linestyle=&#39;--&#39;, color=&#39;r&#39;)
    plt.title(&#39;ACF&#39;)
    plt.xlabel(&#39;time lag&#39;)
    plt.ylabel(&#39;ACF value&#39;)

    plt.subplot(133)
    plt.stem(lag_pacf, linefmt=&#39;skyblue&#39;, markerfmt=&#39;d&#39;)
    plt.axhline(y=0, linestyle=&#39;--&#39;)
    plt.axhline(y=-1.96 / np.sqrt(len(series)), linestyle=&#39;--&#39;, color=&#39;r&#39;)
    plt.axhline(y=1.96 / np.sqrt(len(series)), linestyle=&#39;--&#39;, color=&#39;r&#39;)
    plt.title(&#39;PACF&#39;)
    plt.xlabel(&#39;time lag&#39;)
    plt.ylabel(&#39;PACF value&#39;)

    # identify significant values for ACF
    D_acf = pd.DataFrame(lag_acf, columns=[&#39;ACF&#39;])
    D_acf[&#39;ORDER&#39;] = D_acf.index.values + 1

    min_sign = -1.96 / np.sqrt(len(series))
    max_sign = 1.96 / np.sqrt(len(series))

    D_acf[&#39;SIGNIFICANT&#39;] = (D_acf[&#39;ACF&#39;] &gt; max_sign) | (D_acf[&#39;ACF&#39;] &lt; min_sign)
    D_acf_significant = D_acf[&#39;ORDER&#39;][D_acf[&#39;SIGNIFICANT&#39;]].values

    # identify significant values for PACF
    D_pacf = pd.DataFrame(lag_pacf, columns=[&#39;PACF&#39;])
    D_pacf[&#39;ORDER&#39;] = D_pacf.index.values + 1

    D_pacf[&#39;SIGNIFICANT&#39;] = (D_pacf[&#39;PACF&#39;] &gt; max_sign) | (D_pacf[&#39;PACF&#39;] &lt; min_sign)
    D_pacf_significant = D_pacf[&#39;ORDER&#39;][D_pacf[&#39;SIGNIFICANT&#39;]].values

    return fig, D_acf_significant, D_pacf_significant


def returnSignificantLags(D_pacf_significant: pd.Series,
                          D_acf_significant: pd.Series,
                          maxValuesSelected: int = 2) -&gt; list:
    &#34;&#34;&#34;
    This function returns tuples of significant order (p, d, q) based on the lags of the function ACF_PACF_plot

    :param D_pacf_significant: DESCRIPTION significant lags of the PACF function, like in the output of ACF_PACF_plot function
    :type D_pacf_significant: pd.Series
    :param D_acf_significant: DESCRIPTION significant lags of the ACF function, like in the output of ACF_PACF_plot function
    :type D_acf_significant: pd.Series
    :param maxValuesSelected: DESCRIPTION, defaults to 2. Number of combinations of p, d, and q to produce
    :type maxValuesSelected: int, optional
    :return: DESCRIPTION multidimensional list with combinations of (p, d, q) for ARIMA fitting
    :rtype: list

    &#34;&#34;&#34;
    # Select values for parameter p
    if len(D_pacf_significant) &gt; 1:
        numSelected = min(maxValuesSelected, len(D_pacf_significant))
        p = D_pacf_significant[0: numSelected]

    else:
        p = [0, 1]

    # Select values for parameter q
    if len(D_acf_significant) &gt; 1:
        numSelected = min(maxValuesSelected, len(D_acf_significant))
        q = D_acf_significant[0: numSelected]
    else:
        q = [0, 1]

    d = [0, 1]
    a = [p, d, q]
    params = list(itertools.product(*a))
    return params


def detrendByRollingMean(series: pd.Series,
                         seasonalityPeriod: int) -&gt; pd.Series:
    &#34;&#34;&#34;
    Apply detrending by using a rolling mean
    :param series: DESCRIPTION input pandas series
    :type series: pd.Series
    :param seasonalityPeriod: DESCRIPTION window of the rolling mean
    :type seasonalityPeriod: int
    :return: DESCRIPTION output detrended series
    :rtype: TYPE

    &#34;&#34;&#34;
    rolling_mean = series.rolling(window=seasonalityPeriod).mean()
    detrended = series.Series - rolling_mean
    return detrended


def SARIMAXfit(stationary_series: pd.Series,
               params: list) -&gt; tuple:
    &#34;&#34;&#34;
    this function tries different SARIMAX fits using tuples of orders specified in the list of tuples (p,d,q) param
    on the time series stationary_series
    the function return a figure_forecast with the plot of the forecast
    a figure_residuals with the plot of the residuals
    a dict resultModel with the model, the error (AIC), the order p,d,q

    PACF=&gt;AR
    ACF=&gt;MA
    ARIMA(P,D,Q) = ARIMA(AR, I, MA)

    :param stationary_series: DESCRIPTION input pandas series to fit
    :type stationary_series: pd.series
    :param params: DESCRIPTION (p, d, q) parameters to fit the SARIMAX model, as output of returnSignificantLags function
    :type params: list
    :return: DESCRIPTION tuple with output
    :rtype: tuple

    &#34;&#34;&#34;

    # Set an initial dummy error
    incumbentError = 999999999999999999999
    bestModel = []

    for param in params:
        mod = sm.tsa.statespace.SARIMAX(stationary_series,
                                        order=param,
                                        enforce_stationarity=True,
                                        enforce_invertibility=True,
                                        initialization=&#39;approximate_diffuse&#39;)

        results = mod.fit()
        if(results.aic &lt; incumbentError):
            bestModel = mod
            incumbentError = results.aic

    # save the best fit model
    results = bestModel.fit()
    figure_residuals = results.plot_diagnostics(figsize=(15, 12))

    # Produce output figure
    figure_forecast = plt.figure()
    plt.plot(stationary_series)
    plt.plot(results.fittedvalues, color=&#39;red&#39;)
    plt.title(&#39;ARIMA fit p=&#39; + str(bestModel.k_ar) + &#39; d=&#39; + str(bestModel.k_diff) + &#39; q=&#39; + str(bestModel.k_ma))

    resultModel = {&#39;model&#39;: bestModel,
                   &#39;aic&#39;: incumbentError,
                   &#39;p&#39;: bestModel.k_ar,
                   &#39;d&#39;: bestModel.k_diff,
                   &#39;q&#39;: bestModel.k_ma}

    return figure_forecast, figure_residuals, resultModel


def ARIMAfit(series: pd.Series,
             p: int,
             d: int,
             q: int) -&gt; bool:
    &#34;&#34;&#34;

    :param series: DESCRIPTION input pandas series to fit
    :type series: pd. series
    :param p: DESCRIPTION ARIMA parameter P
    :type p: int
    :param d: DESCRIPTION ARIMA parameter D
    :type d: int
    :param q: DESCRIPTION ARIMA parameter Q
    :type q: int
    :return: DESCRIPTION
    :rtype: bool

    &#34;&#34;&#34;

    model = ARIMA(series, order=(p, d, q))
    results_AR = model.fit(disp=-1)
    plt.plot(series)
    plt.plot(results_AR.fittedvalues, color=&#39;red&#39;)
    plt.title(&#39;ARIMA fit p=&#39; + str(p) + &#39; q=&#39; + str(q) + &#39; d=&#39; + str(d))

    # Plot output figure
    plt.figure()
    results_AR.plot_diagnostics(figsize=(15, 12))
    return True


def autoSARIMAXfit(y, minRangepdq, maxRangepdqy, seasonality):
    minRangepdq = np.int(minRangepdq)
    maxRangepdqy = np.int(maxRangepdqy)
    seasonality = np.int(seasonality)

    # Define the p, d and q parameters to take any value between 0 and 2
    p = d = q = range(minRangepdq, maxRangepdqy)

    # Generate all different combinations of p, q and q triplets
    pdq = list(itertools.product(p, d, q))

    # Generate all different combinations of seasonal p, q and q triplets
    seasonal_pdq = [(x[0], x[1], x[2], seasonality) for x in list(itertools.product(p, d, q))]
    warnings.filterwarnings(&#34;ignore&#34;)  # specify to ignore warning messages

    incumbentError = 9999999999
    for param in pdq:
        for param_seasonal in seasonal_pdq:
            try:
                mod = sm.tsa.statespace.SARIMAX(y,
                                                order=param,
                                                seasonal_order=param_seasonal,
                                                enforce_stationarity=False,
                                                enforce_invertibility=False)

                results = mod.fit()
                if(results.aic &lt; incumbentError):
                    bestModel = mod
                    incumbentError = results.aic

                # print(&#39;ARIMA{}x{}12 - AIC:{}&#39;.format(param, param_seasonal, results.aic))
            except Exception:
                continue
    return bestModel


def forecastSARIMAX(series: pd.Series,
                    minRangepdq: int,
                    maxRangepdqy: int,
                    seasonality: int,
                    NofSteps: int,
                    title: str) -&gt; tuple:
    &#34;&#34;&#34;
    the function test several consecutive values of (p, d, q) using SARIMAX model fitting.
    :param series: DESCRIPTION input pandas series to fit
    :type series: pd.series
    :param minRangepdq: DESCRIPTION minimum value among  (p, d, q) to test
    :type minRangepdq: int
    :param maxRangepdqy: DESCRIPTION maximum value among  (p, d, q) to test
    :type maxRangepdqy: int
    :param seasonality: DESCRIPTION value of seasonality
    :type seasonality: int
    :param NofSteps: DESCRIPTION number of future time points to forecast
    :type NofSteps: int
    :param title: DESCRIPTION title of the output figure
    :type title: str
    :return: DESCRIPTION output tuple
    :rtype: tuple

    &#34;&#34;&#34;

    NofSteps = np.int(NofSteps)
    # residui=plt.figure()
    result = autoSARIMAXfit(series, minRangepdq, maxRangepdqy, seasonality)
    results = result.fit()
    residui = results.plot_diagnostics(figsize=(15, 12))

    forecast = plt.figure()
    pred = results.get_prediction(start=len(series) - 1,
                                  end=len(series) + NofSteps,
                                  dynamic=True)
    pred_ci = pred.conf_int()

    ax = series.plot(label=&#39;observed&#39;, color=&#39;orange&#39;)
    pred.predicted_mean.plot(ax=ax, label=&#39;Dynamic forecast&#39;, color=&#39;r&#39;, style=&#39;--&#39;, alpha=.7)

    ax.fill_between(pred_ci.index,
                    pred_ci.iloc[:, 0],
                    pred_ci.iloc[:, 1], color=&#39;y&#39;, alpha=.2)

    ax.set_xlabel(&#39;Timeline&#39;)
    ax.set_ylabel(&#39;Series value&#39;)
    plt.title(&#39;Forecast: &#39; + title)
    plt.legend()
    return residui, forecast


def fourierAnalysis(y: np.array) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    The function applies the fast Fourier transform to a time series and returna a pandas DataFrame with the significant
    fourier Coefficients
    :param y: DESCRIPTION input array of float
    :type y: np.array
    :return: DESCRIPTION
    :rtype: TYPE pd.DataFrame

    &#34;&#34;&#34;

    y = y.reshape(len(y),)
    N = len(y)
    T = 1  # assume having one sample for each time period

    t = np.arange(0, len(y)).reshape(len(y),)
    p = np.polyfit(t, y, 1)         # find linear trend in x
    y_notrend = y - p[0] * t

    # calculate fourier transform
    yf = np.fft.fft(y_notrend)

    # filter on the most significant coefficients (frequencies explaining at least 10% of the seasonality)
    xf = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)
    amplitude = 2.0 / N * np.abs(yf[0:N // 2])
    weeks = 1 / xf

    data = {&#39;Frequency_domain_value&#39;: xf,
            &#39;Time_domain_value&#39;: weeks,
            &#39;Amplitude&#39;: amplitude}
    D = pd.DataFrame(data)
    D = D.replace([np.inf, -np.inf], np.nan)
    D = D.dropna()
    D = D.sort_values([&#39;Amplitude&#39;], ascending=False)
    D[&#39;perc&#39;] = D[&#39;Amplitude&#39;] / np.sum(D[&#39;Amplitude&#39;])
    D[&#39;cumsum&#39;] = D[&#39;perc&#39;].cumsum()

    return D


def transformSeriesToStationary(series: pd.Series,
                                signifAlpha: float = 0.05) -&gt; tuple:
    &#34;&#34;&#34;
    this function tries log, power and square root transformation to stationary series
    it returns the series and a string with the model used to transform the series
    reference: http://www.insightsbot.com/blog/1MH61d/augmented-dickey-fuller-test-in-python

    :param series: DESCRIPTION pandas series to transform stationary
    :type series: pd.Series
    :param signifAlpha: DESCRIPTION, defaults to 0.05. significance level (0.1 , 0.05, 0.01) to accept or reject the null hypothesis of Dickey fuller
    :type signifAlpha: float, optional
    :return: DESCRIPTION
    :rtype: tuple

    &#34;&#34;&#34;

    def _returnPandPstar(result):
        p_value = result[1]

        p_star = signifAlpha

        # in alternativa si puo&#39; usare il valore della statistica del test e i valori critici
        &#39;&#39;&#39;
        if signifAlpha==0.01:
            p_star=result[4][&#39;1%&#39;]
        elif signifAlpha==0.05:
            p_star=result[4][&#39;5%&#39;]
        if signifAlpha==0.1:
            p_star=result[4][&#39;10%&#39;]
        &#39;&#39;&#39;

        return p_value, p_star

    ###########################################################################
    # test the original series
    result = adfuller(series, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    &#39;&#39;&#39;
    If the P-Value is less than the Significance Level defined,
    we reject the Null Hypothesis that the time series contains a unit root.
    In other words, by rejecting the Null hypothesis,
    we can conclude that the time series is stationary.
    &#39;&#39;&#39;

    if (p_value &lt; p_star):
        print(&#34;The initial series is stationary&#34;)
        model = &#39;initial&#39;
        return series, model

    ###########################################################################
    # trying with power transformation
    series_transformed = series**2

    result = adfuller(series_transformed, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    if (p_value &lt; p_star):
        print(&#34;The transformed series using POWER transformation is stationary&#34;)
        model = &#39;POWER:2&#39;
        return series_transformed, model

    ###########################################################################
    # trying with square root transformation
    series_transformed = np.sqrt(series)

    result = adfuller(series_transformed, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    if (p_value &lt; p_star):
        print(&#34;The transformed series using SQUARE ROOT transformation is stationary&#34;)
        model = &#39;SQRT&#39;
        return series_transformed, model

    ###########################################################################
    # trying with logarithm transformation
    series_temp = series + 0.001
    series_transformed = np.log(series_temp)

    result = adfuller(series_transformed, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    if (p_value &lt; p_star):
        print(&#34;The transformed series using LOG transformation is stationary&#34;)
        model = &#39;LOG&#39;
        return series_transformed, model

    ###########################################################################
    # trying with boxcox transformation
    series_transformed, lam = boxcox(series_temp)

    result = adfuller(series_transformed, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    if (p_value &lt; p_star):
        print(&#34;The transformed series using BOXCOX, lambda:{lam} transformation is stationary&#34;)
        model = f&#34;BOXCOX, lambda:{lam}&#34;
        return series_transformed, model

    print(&#34;No valid transformation found&#34;)
    return [], []


def attractor_estimate(y, dim=&#39;3d&#39;) -&gt; bool:
    &#34;&#34;&#34;
    Uses the Ruelle &amp; Packard method to estimate an attractor
    :param y: DESCRIPTION time series to evaluate
    :type y: TYPE
    :param dim: DESCRIPTION, defaults to &#39;3d&#39;. &#39;3d&#39; or &#39;2d&#39; projection
    :type dim: TYPE, optional
    :return: DESCRIPTION
    :rtype: TYPE

    &#34;&#34;&#34;
    if dim not in [&#39;2d&#39;, &#39;3d&#39;]:
        raise ValueError(f&#34;&#34;&#34;dim parameter: {dim} not a valid projection.
                          Choose between [&#39;2d&#39;, &#39;3d&#39;]&#34;&#34;&#34;)
    # TODO: add the time lag choice
    output_fig = {}

    #  Ruelle &amp; Packard reconstruction
    y_2 = y[1:]
    y_3 = y[2:]

    # fix array length
    y = y[:len(y_3)]
    y_2 = y_2[:len(y_3)]

    if dim == &#39;3d&#39;:
        fig = plt.figure()
        ax = fig.gca(projection=&#39;3d&#39;)
        ax.plot(y, y_2, y_3, lw=0.5)
        plt.title(f&#34; {dim} attractor estimate&#34;)
        output_fig[&#39;attractor_fig&#39;] = fig
    elif dim == &#39;2d&#39;:
        fig = plt.figure()
        plt.plot(y, y_2, lw=0.5)
        plt.title(f&#34; {dim} attractor estimate&#34;)
        output_fig[&#39;attractor_fig&#39;] = fig
    else:
        print(&#34;Choose 3d or 2d dimension&#34;)
    return True


def poincare_section(series: pd.Series,
                     T: int = 2,
                     num_of_dots_on_picture: int = 10) -&gt; tuple:
    &#34;&#34;&#34;
    Define the poincare section of a time series at time lags T and output
    a figure for each time lag containing a given number of dots
    :param series: DESCRIPTION time series to analyse
    :type series: TYPE
    :param T: DESCRIPTION, defaults to 2. time lag at which evaluate the time series
    :type T: TYPE, optional
    :param num_of_dots_on_picture: DESCRIPTION, defaults to 10. number of dots for each image of the poincare section
    :type num_of_dots_on_picture: TYPE, optional
    :return: DESCRIPTION pandas dataframe with poincare section coordinates for each time lag evaluated,
                         corresponding predicted value (next time lag()) and an image (rgb array) with the
                         num_of_dots_on_picture poincare section evaluated at that step

                         dictionary containing the poincare section at the last time lag
    :rtype: TYPE tuple

    &#34;&#34;&#34;

    # create an output dictionary for figures
    out_fig = {}

    # create a dataframe with coordinates of the poincare section
    # the corrensponding predicting value
    D_all_coords = pd.DataFrame(columns=[&#39;x_coord&#39;, &#39;y_coord&#39;, &#39;value_to_predict&#39;])

    # define the poincare section at each time lag
    for i in range(T, len(series) - 1):
        poincare_new_coord = (series[i], series[i - T], series[i + 1])
        D_all_coords = D_all_coords.append(pd.DataFrame([poincare_new_coord],
                                                        columns=[&#39;x_coord&#39;, &#39;y_coord&#39;, &#39;value_to_predict&#39;]))

    # set progressive index
    D_all_coords.index = list(range(0, len(D_all_coords)))

    # plot Poincare Section of the Time series with the given Time Lag

    # set colors
    c_list = list(range(len(D_all_coords)))
    cmap = cm.autumn
    norm = Normalize(vmin=min(c_list), vmax=max(c_list))

    # define the figure
    fig = plt.figure()
    plt.scatter(D_all_coords[&#39;x_coord&#39;], D_all_coords[&#39;y_coord&#39;], s=0.5, c=cmap(norm(c_list)))
    plt.title(f&#34;Poincare section with k={T}&#34;)
    out_fig[&#39;PoincareSection&#39;] = fig

    # output the image arrays for predictions

    # add a column for the images with the poincare sections
    D_all_coords[&#39;PoincareMaps&#39;] = &#39;&#39;
    for position in range(0, len(D_all_coords)):

        beginning = max(0, position - num_of_dots_on_picture)
        end = position + 1
        plt.scatter(D_all_coords[&#39;x_coord&#39;].iloc[beginning:end], D_all_coords[&#39;y_coord&#39;].iloc[beginning:end], s=0.5, c=&#39;black&#39;)
        plt.xlim((min(D_all_coords[&#39;x_coord&#39;]), max(D_all_coords[&#39;x_coord&#39;])))
        plt.ylim((min(D_all_coords[&#39;y_coord&#39;]), max(D_all_coords[&#39;y_coord&#39;])))
        plt.axis(&#39;off&#39;)
        out_fig[&#39;PoincareSection&#39;] = fig
        fig.canvas.draw()

        # Now we can save it to a numpy array.
        data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=&#39;&#39;)
        data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))

        D_all_coords.at[position, &#39;PoincareMaps&#39;] = data

    return D_all_coords, out_fig</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="analogistics.stat_time_series.ACF_PACF_plot"><code class="name flex">
<span>def <span class="ident">ACF_PACF_plot</span></span>(<span>series: pandas.core.series.Series) -> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a graph with a time series, the ACF and the PACF. In addition, it returns
two pandas Series with the significant lags in the ACF and PACF
:param series: DESCRIPTION input pandas series with the observations
:type series: pd.Series
:return: DESCRIPTION output tuple
:rtype: tuple</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ACF_PACF_plot(series: pd.Series) -&gt; tuple:
    &#34;&#34;&#34;
    Creates a graph with a time series, the ACF and the PACF. In addition, it returns
    two pandas Series with the significant lags in the ACF and PACF
    :param series: DESCRIPTION input pandas series with the observations
    :type series: pd.Series
    :return: DESCRIPTION output tuple
    :rtype: tuple

    &#34;&#34;&#34;

    # Prepare the output figure
    fig = plt.subplot(131)

    plt.plot(series, &#39;skyblue&#39;)
    plt.xticks(rotation=30)
    plt.title(&#39;Time Series&#39;)

    lag_acf = acf(series, nlags=20)
    lag_pacf = pacf(series, nlags=20)

    plt.subplot(132)
    plt.stem(lag_acf, linefmt=&#39;skyblue&#39;, markerfmt=&#39;d&#39;)
    plt.axhline(y=0, linestyle=&#39;--&#39;)
    plt.axhline(y=-1.96 / np.sqrt(len(series)), linestyle=&#39;--&#39;, color=&#39;r&#39;)
    plt.axhline(y=1.96 / np.sqrt(len(series)), linestyle=&#39;--&#39;, color=&#39;r&#39;)
    plt.title(&#39;ACF&#39;)
    plt.xlabel(&#39;time lag&#39;)
    plt.ylabel(&#39;ACF value&#39;)

    plt.subplot(133)
    plt.stem(lag_pacf, linefmt=&#39;skyblue&#39;, markerfmt=&#39;d&#39;)
    plt.axhline(y=0, linestyle=&#39;--&#39;)
    plt.axhline(y=-1.96 / np.sqrt(len(series)), linestyle=&#39;--&#39;, color=&#39;r&#39;)
    plt.axhline(y=1.96 / np.sqrt(len(series)), linestyle=&#39;--&#39;, color=&#39;r&#39;)
    plt.title(&#39;PACF&#39;)
    plt.xlabel(&#39;time lag&#39;)
    plt.ylabel(&#39;PACF value&#39;)

    # identify significant values for ACF
    D_acf = pd.DataFrame(lag_acf, columns=[&#39;ACF&#39;])
    D_acf[&#39;ORDER&#39;] = D_acf.index.values + 1

    min_sign = -1.96 / np.sqrt(len(series))
    max_sign = 1.96 / np.sqrt(len(series))

    D_acf[&#39;SIGNIFICANT&#39;] = (D_acf[&#39;ACF&#39;] &gt; max_sign) | (D_acf[&#39;ACF&#39;] &lt; min_sign)
    D_acf_significant = D_acf[&#39;ORDER&#39;][D_acf[&#39;SIGNIFICANT&#39;]].values

    # identify significant values for PACF
    D_pacf = pd.DataFrame(lag_pacf, columns=[&#39;PACF&#39;])
    D_pacf[&#39;ORDER&#39;] = D_pacf.index.values + 1

    D_pacf[&#39;SIGNIFICANT&#39;] = (D_pacf[&#39;PACF&#39;] &gt; max_sign) | (D_pacf[&#39;PACF&#39;] &lt; min_sign)
    D_pacf_significant = D_pacf[&#39;ORDER&#39;][D_pacf[&#39;SIGNIFICANT&#39;]].values

    return fig, D_acf_significant, D_pacf_significant</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.ARIMAfit"><code class="name flex">
<span>def <span class="ident">ARIMAfit</span></span>(<span>series: pandas.core.series.Series, p: int, d: int, q: int) -> bool</span>
</code></dt>
<dd>
<div class="desc"><p>:param series: DESCRIPTION input pandas series to fit
:type series: pd. series
:param p: DESCRIPTION ARIMA parameter P
:type p: int
:param d: DESCRIPTION ARIMA parameter D
:type d: int
:param q: DESCRIPTION ARIMA parameter Q
:type q: int
:return: DESCRIPTION
:rtype: bool</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ARIMAfit(series: pd.Series,
             p: int,
             d: int,
             q: int) -&gt; bool:
    &#34;&#34;&#34;

    :param series: DESCRIPTION input pandas series to fit
    :type series: pd. series
    :param p: DESCRIPTION ARIMA parameter P
    :type p: int
    :param d: DESCRIPTION ARIMA parameter D
    :type d: int
    :param q: DESCRIPTION ARIMA parameter Q
    :type q: int
    :return: DESCRIPTION
    :rtype: bool

    &#34;&#34;&#34;

    model = ARIMA(series, order=(p, d, q))
    results_AR = model.fit(disp=-1)
    plt.plot(series)
    plt.plot(results_AR.fittedvalues, color=&#39;red&#39;)
    plt.title(&#39;ARIMA fit p=&#39; + str(p) + &#39; q=&#39; + str(q) + &#39; d=&#39; + str(d))

    # Plot output figure
    plt.figure()
    results_AR.plot_diagnostics(figsize=(15, 12))
    return True</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.SARIMAXfit"><code class="name flex">
<span>def <span class="ident">SARIMAXfit</span></span>(<span>stationary_series: pandas.core.series.Series, params: list) -> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>this function tries different SARIMAX fits using tuples of orders specified in the list of tuples (p,d,q) param
on the time series stationary_series
the function return a figure_forecast with the plot of the forecast
a figure_residuals with the plot of the residuals
a dict resultModel with the model, the error (AIC), the order p,d,q</p>
<p>PACF=&gt;AR
ACF=&gt;MA
ARIMA(P,D,Q) = ARIMA(AR, I, MA)</p>
<p>:param stationary_series: DESCRIPTION input pandas series to fit
:type stationary_series: pd.series
:param params: DESCRIPTION (p, d, q) parameters to fit the SARIMAX model, as output of returnSignificantLags function
:type params: list
:return: DESCRIPTION tuple with output
:rtype: tuple</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SARIMAXfit(stationary_series: pd.Series,
               params: list) -&gt; tuple:
    &#34;&#34;&#34;
    this function tries different SARIMAX fits using tuples of orders specified in the list of tuples (p,d,q) param
    on the time series stationary_series
    the function return a figure_forecast with the plot of the forecast
    a figure_residuals with the plot of the residuals
    a dict resultModel with the model, the error (AIC), the order p,d,q

    PACF=&gt;AR
    ACF=&gt;MA
    ARIMA(P,D,Q) = ARIMA(AR, I, MA)

    :param stationary_series: DESCRIPTION input pandas series to fit
    :type stationary_series: pd.series
    :param params: DESCRIPTION (p, d, q) parameters to fit the SARIMAX model, as output of returnSignificantLags function
    :type params: list
    :return: DESCRIPTION tuple with output
    :rtype: tuple

    &#34;&#34;&#34;

    # Set an initial dummy error
    incumbentError = 999999999999999999999
    bestModel = []

    for param in params:
        mod = sm.tsa.statespace.SARIMAX(stationary_series,
                                        order=param,
                                        enforce_stationarity=True,
                                        enforce_invertibility=True,
                                        initialization=&#39;approximate_diffuse&#39;)

        results = mod.fit()
        if(results.aic &lt; incumbentError):
            bestModel = mod
            incumbentError = results.aic

    # save the best fit model
    results = bestModel.fit()
    figure_residuals = results.plot_diagnostics(figsize=(15, 12))

    # Produce output figure
    figure_forecast = plt.figure()
    plt.plot(stationary_series)
    plt.plot(results.fittedvalues, color=&#39;red&#39;)
    plt.title(&#39;ARIMA fit p=&#39; + str(bestModel.k_ar) + &#39; d=&#39; + str(bestModel.k_diff) + &#39; q=&#39; + str(bestModel.k_ma))

    resultModel = {&#39;model&#39;: bestModel,
                   &#39;aic&#39;: incumbentError,
                   &#39;p&#39;: bestModel.k_ar,
                   &#39;d&#39;: bestModel.k_diff,
                   &#39;q&#39;: bestModel.k_ma}

    return figure_forecast, figure_residuals, resultModel</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.assignWeekDay"><code class="name flex">
<span>def <span class="ident">assignWeekDay</span></span>(<span>df: pandas.core.frame.DataFrame, timeVariable: str) -> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Return the day of the week, and a boolean indicating whether the day is in the weekend
:param df: DESCRIPTION input pandas dataframe
:type df: pd.DataFrame
:param timeVariable: DESCRIPTION column name corresponding to the time variable
:type timeVariable: str
:return: DESCRIPTION tuple with the day of the week, and a boolean for weekend
:rtype: tuple</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assignWeekDay(df: pd.DataFrame,
                  timeVariable: str) -&gt; tuple:
    &#34;&#34;&#34;
    Return the day of the week, and a boolean indicating whether the day is in the weekend
    :param df: DESCRIPTION input pandas dataframe
    :type df: pd.DataFrame
    :param timeVariable: DESCRIPTION column name corresponding to the time variable
    :type timeVariable: str
    :return: DESCRIPTION tuple with the day of the week, and a boolean for weekend
    :rtype: tuple

    &#34;&#34;&#34;
    dayOfTheWeek = df[timeVariable].dt.weekday_name
    weekend = (dayOfTheWeek == &#39;Sunday&#39;) | (dayOfTheWeek == &#39;Saturday&#39;)
    weekEnd = weekend.copy()
    weekEnd[weekend] = &#39;Weekend&#39;
    weekEnd[~weekend] = &#39;Weekday&#39;
    return dayOfTheWeek, weekEnd</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.attractor_estimate"><code class="name flex">
<span>def <span class="ident">attractor_estimate</span></span>(<span>y, dim='3d') -> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Uses the Ruelle &amp; Packard method to estimate an attractor
:param y: DESCRIPTION time series to evaluate
:type y: TYPE
:param dim: DESCRIPTION, defaults to '3d'. '3d' or '2d' projection
:type dim: TYPE, optional
:return: DESCRIPTION
:rtype: TYPE</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def attractor_estimate(y, dim=&#39;3d&#39;) -&gt; bool:
    &#34;&#34;&#34;
    Uses the Ruelle &amp; Packard method to estimate an attractor
    :param y: DESCRIPTION time series to evaluate
    :type y: TYPE
    :param dim: DESCRIPTION, defaults to &#39;3d&#39;. &#39;3d&#39; or &#39;2d&#39; projection
    :type dim: TYPE, optional
    :return: DESCRIPTION
    :rtype: TYPE

    &#34;&#34;&#34;
    if dim not in [&#39;2d&#39;, &#39;3d&#39;]:
        raise ValueError(f&#34;&#34;&#34;dim parameter: {dim} not a valid projection.
                          Choose between [&#39;2d&#39;, &#39;3d&#39;]&#34;&#34;&#34;)
    # TODO: add the time lag choice
    output_fig = {}

    #  Ruelle &amp; Packard reconstruction
    y_2 = y[1:]
    y_3 = y[2:]

    # fix array length
    y = y[:len(y_3)]
    y_2 = y_2[:len(y_3)]

    if dim == &#39;3d&#39;:
        fig = plt.figure()
        ax = fig.gca(projection=&#39;3d&#39;)
        ax.plot(y, y_2, y_3, lw=0.5)
        plt.title(f&#34; {dim} attractor estimate&#34;)
        output_fig[&#39;attractor_fig&#39;] = fig
    elif dim == &#39;2d&#39;:
        fig = plt.figure()
        plt.plot(y, y_2, lw=0.5)
        plt.title(f&#34; {dim} attractor estimate&#34;)
        output_fig[&#39;attractor_fig&#39;] = fig
    else:
        print(&#34;Choose 3d or 2d dimension&#34;)
    return True</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.autoSARIMAXfit"><code class="name flex">
<span>def <span class="ident">autoSARIMAXfit</span></span>(<span>y, minRangepdq, maxRangepdqy, seasonality)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def autoSARIMAXfit(y, minRangepdq, maxRangepdqy, seasonality):
    minRangepdq = np.int(minRangepdq)
    maxRangepdqy = np.int(maxRangepdqy)
    seasonality = np.int(seasonality)

    # Define the p, d and q parameters to take any value between 0 and 2
    p = d = q = range(minRangepdq, maxRangepdqy)

    # Generate all different combinations of p, q and q triplets
    pdq = list(itertools.product(p, d, q))

    # Generate all different combinations of seasonal p, q and q triplets
    seasonal_pdq = [(x[0], x[1], x[2], seasonality) for x in list(itertools.product(p, d, q))]
    warnings.filterwarnings(&#34;ignore&#34;)  # specify to ignore warning messages

    incumbentError = 9999999999
    for param in pdq:
        for param_seasonal in seasonal_pdq:
            try:
                mod = sm.tsa.statespace.SARIMAX(y,
                                                order=param,
                                                seasonal_order=param_seasonal,
                                                enforce_stationarity=False,
                                                enforce_invertibility=False)

                results = mod.fit()
                if(results.aic &lt; incumbentError):
                    bestModel = mod
                    incumbentError = results.aic

                # print(&#39;ARIMA{}x{}12 - AIC:{}&#39;.format(param, param_seasonal, results.aic))
            except Exception:
                continue
    return bestModel</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.detrendByRollingMean"><code class="name flex">
<span>def <span class="ident">detrendByRollingMean</span></span>(<span>series: pandas.core.series.Series, seasonalityPeriod: int) -> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Apply detrending by using a rolling mean
:param series: DESCRIPTION input pandas series
:type series: pd.Series
:param seasonalityPeriod: DESCRIPTION window of the rolling mean
:type seasonalityPeriod: int
:return: DESCRIPTION output detrended series
:rtype: TYPE</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def detrendByRollingMean(series: pd.Series,
                         seasonalityPeriod: int) -&gt; pd.Series:
    &#34;&#34;&#34;
    Apply detrending by using a rolling mean
    :param series: DESCRIPTION input pandas series
    :type series: pd.Series
    :param seasonalityPeriod: DESCRIPTION window of the rolling mean
    :type seasonalityPeriod: int
    :return: DESCRIPTION output detrended series
    :rtype: TYPE

    &#34;&#34;&#34;
    rolling_mean = series.rolling(window=seasonalityPeriod).mean()
    detrended = series.Series - rolling_mean
    return detrended</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.forecastSARIMAX"><code class="name flex">
<span>def <span class="ident">forecastSARIMAX</span></span>(<span>series: pandas.core.series.Series, minRangepdq: int, maxRangepdqy: int, seasonality: int, NofSteps: int, title: str) -> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>the function test several consecutive values of (p, d, q) using SARIMAX model fitting.
:param series: DESCRIPTION input pandas series to fit
:type series: pd.series
:param minRangepdq: DESCRIPTION minimum value among
(p, d, q) to test
:type minRangepdq: int
:param maxRangepdqy: DESCRIPTION maximum value among
(p, d, q) to test
:type maxRangepdqy: int
:param seasonality: DESCRIPTION value of seasonality
:type seasonality: int
:param NofSteps: DESCRIPTION number of future time points to forecast
:type NofSteps: int
:param title: DESCRIPTION title of the output figure
:type title: str
:return: DESCRIPTION output tuple
:rtype: tuple</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forecastSARIMAX(series: pd.Series,
                    minRangepdq: int,
                    maxRangepdqy: int,
                    seasonality: int,
                    NofSteps: int,
                    title: str) -&gt; tuple:
    &#34;&#34;&#34;
    the function test several consecutive values of (p, d, q) using SARIMAX model fitting.
    :param series: DESCRIPTION input pandas series to fit
    :type series: pd.series
    :param minRangepdq: DESCRIPTION minimum value among  (p, d, q) to test
    :type minRangepdq: int
    :param maxRangepdqy: DESCRIPTION maximum value among  (p, d, q) to test
    :type maxRangepdqy: int
    :param seasonality: DESCRIPTION value of seasonality
    :type seasonality: int
    :param NofSteps: DESCRIPTION number of future time points to forecast
    :type NofSteps: int
    :param title: DESCRIPTION title of the output figure
    :type title: str
    :return: DESCRIPTION output tuple
    :rtype: tuple

    &#34;&#34;&#34;

    NofSteps = np.int(NofSteps)
    # residui=plt.figure()
    result = autoSARIMAXfit(series, minRangepdq, maxRangepdqy, seasonality)
    results = result.fit()
    residui = results.plot_diagnostics(figsize=(15, 12))

    forecast = plt.figure()
    pred = results.get_prediction(start=len(series) - 1,
                                  end=len(series) + NofSteps,
                                  dynamic=True)
    pred_ci = pred.conf_int()

    ax = series.plot(label=&#39;observed&#39;, color=&#39;orange&#39;)
    pred.predicted_mean.plot(ax=ax, label=&#39;Dynamic forecast&#39;, color=&#39;r&#39;, style=&#39;--&#39;, alpha=.7)

    ax.fill_between(pred_ci.index,
                    pred_ci.iloc[:, 0],
                    pred_ci.iloc[:, 1], color=&#39;y&#39;, alpha=.2)

    ax.set_xlabel(&#39;Timeline&#39;)
    ax.set_ylabel(&#39;Series value&#39;)
    plt.title(&#39;Forecast: &#39; + title)
    plt.legend()
    return residui, forecast</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.fourierAnalysis"><code class="name flex">
<span>def <span class="ident">fourierAnalysis</span></span>(<span>y: <built-in function array>) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>The function applies the fast Fourier transform to a time series and returna a pandas DataFrame with the significant
fourier Coefficients
:param y: DESCRIPTION input array of float
:type y: np.array
:return: DESCRIPTION
:rtype: TYPE pd.DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fourierAnalysis(y: np.array) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    The function applies the fast Fourier transform to a time series and returna a pandas DataFrame with the significant
    fourier Coefficients
    :param y: DESCRIPTION input array of float
    :type y: np.array
    :return: DESCRIPTION
    :rtype: TYPE pd.DataFrame

    &#34;&#34;&#34;

    y = y.reshape(len(y),)
    N = len(y)
    T = 1  # assume having one sample for each time period

    t = np.arange(0, len(y)).reshape(len(y),)
    p = np.polyfit(t, y, 1)         # find linear trend in x
    y_notrend = y - p[0] * t

    # calculate fourier transform
    yf = np.fft.fft(y_notrend)

    # filter on the most significant coefficients (frequencies explaining at least 10% of the seasonality)
    xf = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)
    amplitude = 2.0 / N * np.abs(yf[0:N // 2])
    weeks = 1 / xf

    data = {&#39;Frequency_domain_value&#39;: xf,
            &#39;Time_domain_value&#39;: weeks,
            &#39;Amplitude&#39;: amplitude}
    D = pd.DataFrame(data)
    D = D.replace([np.inf, -np.inf], np.nan)
    D = D.dropna()
    D = D.sort_values([&#39;Amplitude&#39;], ascending=False)
    D[&#39;perc&#39;] = D[&#39;Amplitude&#39;] / np.sum(D[&#39;Amplitude&#39;])
    D[&#39;cumsum&#39;] = D[&#39;perc&#39;].cumsum()

    return D</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.groupPerMonth"><code class="name flex">
<span>def <span class="ident">groupPerMonth</span></span>(<span>df: pandas.core.frame.DataFrame, timeVariable: str, groupVariable: str, groupType: str) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Perform a monthly groupby based on a datetime variable, applying a specific type of grouping
:param df: DESCRIPTION input pandas dataframe
:type df: pd.DataFrame
:param timeVariable: DESCRIPTION column name corresponding to the time variable
:type timeVariable: str
:param groupVariable: DESCRIPTION column name corresponding to the grouping variable
:type groupVariable: str
:param groupType: DESCRIPTION type of grouping function
:type groupType: str
:return: DESCRIPTION Output grouped DataFrame
:rtype: TYPE pd.DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def groupPerMonth(df: pd.DataFrame,
                  timeVariable: str,
                  groupVariable: str,
                  groupType: str) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Perform a monthly groupby based on a datetime variable, applying a specific type of grouping
    :param df: DESCRIPTION input pandas dataframe
    :type df: pd.DataFrame
    :param timeVariable: DESCRIPTION column name corresponding to the time variable
    :type timeVariable: str
    :param groupVariable: DESCRIPTION column name corresponding to the grouping variable
    :type groupVariable: str
    :param groupType: DESCRIPTION type of grouping function
    :type groupType: str
    :return: DESCRIPTION Output grouped DataFrame
    :rtype: TYPE pd.DataFrame

    &#34;&#34;&#34;

    if groupType not in [&#39;count&#39;, &#39;sum&#39;]:
        raise ValueError(f&#34;&#34;&#34;groupType parameter: {groupType} not a valid grouping function.
                          Choose between [&#39;count&#39;, &#39;sum&#39;]&#34;&#34;&#34;)

    if isinstance(df, pd.Series):  # convert to dataframe if a series
        df = pd.DataFrame([[df.index.values.T, df.values]],
                          columns=[timeVariable, groupVariable])

    # df[&#39;DatePeriod&#39;] = pd.to_datetime(df[timeVariable]) - pd.to_timedelta(7, unit=&#39;d&#39;)

    if groupType == &#39;count&#39;:
        df = df.groupby([pd.Grouper(key=timeVariable, freq=&#39;M&#39;)])[groupVariable].size()
    elif groupType == &#39;sum&#39;:
        df = df.groupby([pd.Grouper(key=timeVariable, freq=&#39;M&#39;)])[groupVariable].sum()
    df = df.sort_index()
    return df</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.groupPerWeek"><code class="name flex">
<span>def <span class="ident">groupPerWeek</span></span>(<span>df: pandas.core.frame.DataFrame, timeVariable: str, groupVariable: str, groupType: str) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Perform a weekly groupby based on a datetime variable, applying a specific type of grouping
:param df: DESCRIPTION input pandas dataframe
:type df: pd.DataFrame
:param timeVariable: DESCRIPTION column name corresponding to the time variable
:type timeVariable: str
:param groupVariable: DESCRIPTION column name corresponding to the grouping variable
:type groupVariable: str
:param groupType: DESCRIPTION type of grouping function
:type groupType: str
:return: DESCRIPTION Output grouped DataFrame
:rtype: TYPE pd.DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def groupPerWeek(df: pd.DataFrame,
                 timeVariable: str,
                 groupVariable: str,
                 groupType: str) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Perform a weekly groupby based on a datetime variable, applying a specific type of grouping
    :param df: DESCRIPTION input pandas dataframe
    :type df: pd.DataFrame
    :param timeVariable: DESCRIPTION column name corresponding to the time variable
    :type timeVariable: str
    :param groupVariable: DESCRIPTION column name corresponding to the grouping variable
    :type groupVariable: str
    :param groupType: DESCRIPTION type of grouping function
    :type groupType: str
    :return: DESCRIPTION Output grouped DataFrame
    :rtype: TYPE pd.DataFrame

    &#34;&#34;&#34;

    if groupType not in [&#39;count&#39;, &#39;sum&#39;]:
        raise ValueError(f&#34;&#34;&#34;groupType parameter: {groupType} not a valid grouping function.
                          Choose between [&#39;count&#39;, &#39;sum&#39;]&#34;&#34;&#34;)

    # convert to dataframe if a series
    if isinstance(df, pd.Series):
        df = pd.DataFrame([[df.index.values.T, df.values]],
                          columns=[timeVariable, groupVariable])

    df[&#39;DatePeriod&#39;] = pd.to_datetime(df[timeVariable]) - pd.to_timedelta(7, unit=&#39;d&#39;)

    if groupType == &#39;count&#39;:
        df = df.groupby([pd.Grouper(key=timeVariable,
                                    freq=&#39;W-MON&#39;)])[groupVariable].size()
    elif groupType == &#39;sum&#39;:
        df = df.groupby([pd.Grouper(key=timeVariable,
                                    freq=&#39;W-MON&#39;)])[groupVariable].sum()
    df = df.sort_index()
    return df</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.groupPerWeekday"><code class="name flex">
<span>def <span class="ident">groupPerWeekday</span></span>(<span>df: pandas.core.frame.DataFrame, timeVariable: str, groupVariable: str) -> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Perform a groupby per weekday based on a datetime variable, applying a specific type of grouping
:param df: DESCRIPTION input pandas dataframe
:type df: pd.DataFrame
:param timeVariable: DESCRIPTION column name corresponding to the time variable
:type timeVariable: str
:param groupVariable: DESCRIPTION column name corresponding to the grouping variable
:type groupVariable: str
:return: DESCRIPTION Output grouped DataFrame
:rtype: TYPE pd.DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def groupPerWeekday(df: pd.DataFrame,
                    timeVariable: str,
                    groupVariable: str) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Perform a groupby per weekday based on a datetime variable, applying a specific type of grouping
    :param df: DESCRIPTION input pandas dataframe
    :type df: pd.DataFrame
    :param timeVariable: DESCRIPTION column name corresponding to the time variable
    :type timeVariable: str
    :param groupVariable: DESCRIPTION column name corresponding to the grouping variable
    :type groupVariable: str
    :return: DESCRIPTION Output grouped DataFrame
    :rtype: TYPE pd.DataFrame

    &#34;&#34;&#34;

    cats = [&#39;Monday&#39;, &#39;Tuesday&#39;, &#39;Wednesday&#39;, &#39;Thursday&#39;, &#39;Friday&#39;, &#39;Saturday&#39;, &#39;Sunday&#39;]
    cat_type = CategoricalDtype(categories=cats, ordered=True)

    df[&#39;Weekday&#39;] = df[timeVariable].dt.day_name()
    df[&#39;Weekday&#39;] = df[&#39;Weekday&#39;].astype(cat_type)
    D_grouped = df.groupby([&#39;Weekday&#39;]).agg({groupVariable: [&#39;size&#39;, &#39;mean&#39;, &#39;std&#39;]})
    D_grouped.columns = D_grouped.columns.droplevel(0)
    D_grouped[&#39;mean&#39;] = np.round(D_grouped[&#39;mean&#39;], 2)
    D_grouped[&#39;std&#39;] = np.round(D_grouped[&#39;std&#39;], 2)
    return D_grouped</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.poincare_section"><code class="name flex">
<span>def <span class="ident">poincare_section</span></span>(<span>series: pandas.core.series.Series, T: int = 2, num_of_dots_on_picture: int = 10) -> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Define the poincare section of a time series at time lags T and output
a figure for each time lag containing a given number of dots
:param series: DESCRIPTION time series to analyse
:type series: TYPE
:param T: DESCRIPTION, defaults to 2. time lag at which evaluate the time series
:type T: TYPE, optional
:param num_of_dots_on_picture: DESCRIPTION, defaults to 10. number of dots for each image of the poincare section
:type num_of_dots_on_picture: TYPE, optional
:return: DESCRIPTION pandas dataframe with poincare section coordinates for each time lag evaluated,
corresponding predicted value (next time lag()) and an image (rgb array) with the
num_of_dots_on_picture poincare section evaluated at that step</p>
<pre><code>                 dictionary containing the poincare section at the last time lag
</code></pre>
<p>:rtype: TYPE tuple</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def poincare_section(series: pd.Series,
                     T: int = 2,
                     num_of_dots_on_picture: int = 10) -&gt; tuple:
    &#34;&#34;&#34;
    Define the poincare section of a time series at time lags T and output
    a figure for each time lag containing a given number of dots
    :param series: DESCRIPTION time series to analyse
    :type series: TYPE
    :param T: DESCRIPTION, defaults to 2. time lag at which evaluate the time series
    :type T: TYPE, optional
    :param num_of_dots_on_picture: DESCRIPTION, defaults to 10. number of dots for each image of the poincare section
    :type num_of_dots_on_picture: TYPE, optional
    :return: DESCRIPTION pandas dataframe with poincare section coordinates for each time lag evaluated,
                         corresponding predicted value (next time lag()) and an image (rgb array) with the
                         num_of_dots_on_picture poincare section evaluated at that step

                         dictionary containing the poincare section at the last time lag
    :rtype: TYPE tuple

    &#34;&#34;&#34;

    # create an output dictionary for figures
    out_fig = {}

    # create a dataframe with coordinates of the poincare section
    # the corrensponding predicting value
    D_all_coords = pd.DataFrame(columns=[&#39;x_coord&#39;, &#39;y_coord&#39;, &#39;value_to_predict&#39;])

    # define the poincare section at each time lag
    for i in range(T, len(series) - 1):
        poincare_new_coord = (series[i], series[i - T], series[i + 1])
        D_all_coords = D_all_coords.append(pd.DataFrame([poincare_new_coord],
                                                        columns=[&#39;x_coord&#39;, &#39;y_coord&#39;, &#39;value_to_predict&#39;]))

    # set progressive index
    D_all_coords.index = list(range(0, len(D_all_coords)))

    # plot Poincare Section of the Time series with the given Time Lag

    # set colors
    c_list = list(range(len(D_all_coords)))
    cmap = cm.autumn
    norm = Normalize(vmin=min(c_list), vmax=max(c_list))

    # define the figure
    fig = plt.figure()
    plt.scatter(D_all_coords[&#39;x_coord&#39;], D_all_coords[&#39;y_coord&#39;], s=0.5, c=cmap(norm(c_list)))
    plt.title(f&#34;Poincare section with k={T}&#34;)
    out_fig[&#39;PoincareSection&#39;] = fig

    # output the image arrays for predictions

    # add a column for the images with the poincare sections
    D_all_coords[&#39;PoincareMaps&#39;] = &#39;&#39;
    for position in range(0, len(D_all_coords)):

        beginning = max(0, position - num_of_dots_on_picture)
        end = position + 1
        plt.scatter(D_all_coords[&#39;x_coord&#39;].iloc[beginning:end], D_all_coords[&#39;y_coord&#39;].iloc[beginning:end], s=0.5, c=&#39;black&#39;)
        plt.xlim((min(D_all_coords[&#39;x_coord&#39;]), max(D_all_coords[&#39;x_coord&#39;])))
        plt.ylim((min(D_all_coords[&#39;y_coord&#39;]), max(D_all_coords[&#39;y_coord&#39;])))
        plt.axis(&#39;off&#39;)
        out_fig[&#39;PoincareSection&#39;] = fig
        fig.canvas.draw()

        # Now we can save it to a numpy array.
        data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=&#39;&#39;)
        data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))

        D_all_coords.at[position, &#39;PoincareMaps&#39;] = data

    return D_all_coords, out_fig</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.returnSignificantLags"><code class="name flex">
<span>def <span class="ident">returnSignificantLags</span></span>(<span>D_pacf_significant: pandas.core.series.Series, D_acf_significant: pandas.core.series.Series, maxValuesSelected: int = 2) -> list</span>
</code></dt>
<dd>
<div class="desc"><p>This function returns tuples of significant order (p, d, q) based on the lags of the function ACF_PACF_plot</p>
<p>:param D_pacf_significant: DESCRIPTION significant lags of the PACF function, like in the output of ACF_PACF_plot function
:type D_pacf_significant: pd.Series
:param D_acf_significant: DESCRIPTION significant lags of the ACF function, like in the output of ACF_PACF_plot function
:type D_acf_significant: pd.Series
:param maxValuesSelected: DESCRIPTION, defaults to 2. Number of combinations of p, d, and q to produce
:type maxValuesSelected: int, optional
:return: DESCRIPTION multidimensional list with combinations of (p, d, q) for ARIMA fitting
:rtype: list</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def returnSignificantLags(D_pacf_significant: pd.Series,
                          D_acf_significant: pd.Series,
                          maxValuesSelected: int = 2) -&gt; list:
    &#34;&#34;&#34;
    This function returns tuples of significant order (p, d, q) based on the lags of the function ACF_PACF_plot

    :param D_pacf_significant: DESCRIPTION significant lags of the PACF function, like in the output of ACF_PACF_plot function
    :type D_pacf_significant: pd.Series
    :param D_acf_significant: DESCRIPTION significant lags of the ACF function, like in the output of ACF_PACF_plot function
    :type D_acf_significant: pd.Series
    :param maxValuesSelected: DESCRIPTION, defaults to 2. Number of combinations of p, d, and q to produce
    :type maxValuesSelected: int, optional
    :return: DESCRIPTION multidimensional list with combinations of (p, d, q) for ARIMA fitting
    :rtype: list

    &#34;&#34;&#34;
    # Select values for parameter p
    if len(D_pacf_significant) &gt; 1:
        numSelected = min(maxValuesSelected, len(D_pacf_significant))
        p = D_pacf_significant[0: numSelected]

    else:
        p = [0, 1]

    # Select values for parameter q
    if len(D_acf_significant) &gt; 1:
        numSelected = min(maxValuesSelected, len(D_acf_significant))
        q = D_acf_significant[0: numSelected]
    else:
        q = [0, 1]

    d = [0, 1]
    a = [p, d, q]
    params = list(itertools.product(*a))
    return params</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.sampleTimeSeries"><code class="name flex">
<span>def <span class="ident">sampleTimeSeries</span></span>(<span>series: pandas.core.series.Series, sampleInterval: str) -> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Sample a pandas series using a sampling interval
:param series: DESCRIPTION input pandas datetime series
:type series: pd.Series
:param sampleInterval: DESCRIPTION type of sampling required
:type sampleInterval: str
:raises ValueError: DESCRIPTION error in case of invalid sampling parameter
:return: DESCRIPTION Output sampled seried
:rtype: TYPE pd.Series</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sampleTimeSeries(series: pd.Series,
                     sampleInterval: str) -&gt; pd.Series:
    &#34;&#34;&#34;
    Sample a pandas series using a sampling interval
    :param series: DESCRIPTION input pandas datetime series
    :type series: pd.Series
    :param sampleInterval: DESCRIPTION type of sampling required
    :type sampleInterval: str
    :raises ValueError: DESCRIPTION error in case of invalid sampling parameter
    :return: DESCRIPTION Output sampled seried
    :rtype: TYPE pd.Series

    &#34;&#34;&#34;

    if sampleInterval not in [&#39;day&#39;, &#39;week&#39;, &#39;month&#39;, &#39;year&#39;]:
        raise ValueError(f&#34;&#34;&#34;sampleInterval parameter: {sampleInterval} not a valid sample interval.
                          Choose between [&#39;day&#39;, &#39;week&#39;, &#39;month&#39;, &#39;year&#39;]&#34;&#34;&#34;)
    if sampleInterval == &#39;day&#39;:
        series = series.dt.strftime(&#39;%Y-%j&#39;)
    elif sampleInterval == &#39;week&#39;:
        series = series.dt.strftime(&#39;%Y-%U&#39;)
    elif sampleInterval == &#39;month&#39;:
        series = series.dt.strftime(&#39;%Y-%m&#39;)
    elif sampleInterval == &#39;year&#39;:
        series = series.dt.strftime(&#39;%Y&#39;)
    return series</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.timeStampToDays"><code class="name flex">
<span>def <span class="ident">timeStampToDays</span></span>(<span>series: pandas.core.series.Series) -> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a datetime series into float series with the number of days
:param series: DESCRIPTION input pandas series
:type series: pd.Series
:return: DESCRIPTION pandas series with float of days
:rtype: TYPE pd.Series</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def timeStampToDays(series: pd.Series) -&gt; pd.Series:
    &#34;&#34;&#34;
    Convert a datetime series into float series with the number of days
    :param series: DESCRIPTION input pandas series
    :type series: pd.Series
    :return: DESCRIPTION pandas series with float of days
    :rtype: TYPE pd.Series

    &#34;&#34;&#34;

    D = series.dt.components[&#39;days&#39;]
    H = series.dt.components[&#39;hours&#39;]
    M = series.dt.components[&#39;minutes&#39;]
    result = D + (H / 24) + (M / (60 * 24))
    return result</code></pre>
</details>
</dd>
<dt id="analogistics.stat_time_series.transformSeriesToStationary"><code class="name flex">
<span>def <span class="ident">transformSeriesToStationary</span></span>(<span>series: pandas.core.series.Series, signifAlpha: float = 0.05) -> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>this function tries log, power and square root transformation to stationary series
it returns the series and a string with the model used to transform the series
reference: <a href="http://www.insightsbot.com/blog/1MH61d/augmented-dickey-fuller-test-in-python">http://www.insightsbot.com/blog/1MH61d/augmented-dickey-fuller-test-in-python</a></p>
<p>:param series: DESCRIPTION pandas series to transform stationary
:type series: pd.Series
:param signifAlpha: DESCRIPTION, defaults to 0.05. significance level (0.1 , 0.05, 0.01) to accept or reject the null hypothesis of Dickey fuller
:type signifAlpha: float, optional
:return: DESCRIPTION
:rtype: tuple</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transformSeriesToStationary(series: pd.Series,
                                signifAlpha: float = 0.05) -&gt; tuple:
    &#34;&#34;&#34;
    this function tries log, power and square root transformation to stationary series
    it returns the series and a string with the model used to transform the series
    reference: http://www.insightsbot.com/blog/1MH61d/augmented-dickey-fuller-test-in-python

    :param series: DESCRIPTION pandas series to transform stationary
    :type series: pd.Series
    :param signifAlpha: DESCRIPTION, defaults to 0.05. significance level (0.1 , 0.05, 0.01) to accept or reject the null hypothesis of Dickey fuller
    :type signifAlpha: float, optional
    :return: DESCRIPTION
    :rtype: tuple

    &#34;&#34;&#34;

    def _returnPandPstar(result):
        p_value = result[1]

        p_star = signifAlpha

        # in alternativa si puo&#39; usare il valore della statistica del test e i valori critici
        &#39;&#39;&#39;
        if signifAlpha==0.01:
            p_star=result[4][&#39;1%&#39;]
        elif signifAlpha==0.05:
            p_star=result[4][&#39;5%&#39;]
        if signifAlpha==0.1:
            p_star=result[4][&#39;10%&#39;]
        &#39;&#39;&#39;

        return p_value, p_star

    ###########################################################################
    # test the original series
    result = adfuller(series, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    &#39;&#39;&#39;
    If the P-Value is less than the Significance Level defined,
    we reject the Null Hypothesis that the time series contains a unit root.
    In other words, by rejecting the Null hypothesis,
    we can conclude that the time series is stationary.
    &#39;&#39;&#39;

    if (p_value &lt; p_star):
        print(&#34;The initial series is stationary&#34;)
        model = &#39;initial&#39;
        return series, model

    ###########################################################################
    # trying with power transformation
    series_transformed = series**2

    result = adfuller(series_transformed, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    if (p_value &lt; p_star):
        print(&#34;The transformed series using POWER transformation is stationary&#34;)
        model = &#39;POWER:2&#39;
        return series_transformed, model

    ###########################################################################
    # trying with square root transformation
    series_transformed = np.sqrt(series)

    result = adfuller(series_transformed, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    if (p_value &lt; p_star):
        print(&#34;The transformed series using SQUARE ROOT transformation is stationary&#34;)
        model = &#39;SQRT&#39;
        return series_transformed, model

    ###########################################################################
    # trying with logarithm transformation
    series_temp = series + 0.001
    series_transformed = np.log(series_temp)

    result = adfuller(series_transformed, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    if (p_value &lt; p_star):
        print(&#34;The transformed series using LOG transformation is stationary&#34;)
        model = &#39;LOG&#39;
        return series_transformed, model

    ###########################################################################
    # trying with boxcox transformation
    series_transformed, lam = boxcox(series_temp)

    result = adfuller(series_transformed, autolag=&#39;AIC&#39;)
    p_value, p_star = _returnPandPstar(result)

    if (p_value &lt; p_star):
        print(&#34;The transformed series using BOXCOX, lambda:{lam} transformation is stationary&#34;)
        model = f&#34;BOXCOX, lambda:{lam}&#34;
        return series_transformed, model

    print(&#34;No valid transformation found&#34;)
    return [], []</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="analogistics" href="index.html">analogistics</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="analogistics.stat_time_series.ACF_PACF_plot" href="#analogistics.stat_time_series.ACF_PACF_plot">ACF_PACF_plot</a></code></li>
<li><code><a title="analogistics.stat_time_series.ARIMAfit" href="#analogistics.stat_time_series.ARIMAfit">ARIMAfit</a></code></li>
<li><code><a title="analogistics.stat_time_series.SARIMAXfit" href="#analogistics.stat_time_series.SARIMAXfit">SARIMAXfit</a></code></li>
<li><code><a title="analogistics.stat_time_series.assignWeekDay" href="#analogistics.stat_time_series.assignWeekDay">assignWeekDay</a></code></li>
<li><code><a title="analogistics.stat_time_series.attractor_estimate" href="#analogistics.stat_time_series.attractor_estimate">attractor_estimate</a></code></li>
<li><code><a title="analogistics.stat_time_series.autoSARIMAXfit" href="#analogistics.stat_time_series.autoSARIMAXfit">autoSARIMAXfit</a></code></li>
<li><code><a title="analogistics.stat_time_series.detrendByRollingMean" href="#analogistics.stat_time_series.detrendByRollingMean">detrendByRollingMean</a></code></li>
<li><code><a title="analogistics.stat_time_series.forecastSARIMAX" href="#analogistics.stat_time_series.forecastSARIMAX">forecastSARIMAX</a></code></li>
<li><code><a title="analogistics.stat_time_series.fourierAnalysis" href="#analogistics.stat_time_series.fourierAnalysis">fourierAnalysis</a></code></li>
<li><code><a title="analogistics.stat_time_series.groupPerMonth" href="#analogistics.stat_time_series.groupPerMonth">groupPerMonth</a></code></li>
<li><code><a title="analogistics.stat_time_series.groupPerWeek" href="#analogistics.stat_time_series.groupPerWeek">groupPerWeek</a></code></li>
<li><code><a title="analogistics.stat_time_series.groupPerWeekday" href="#analogistics.stat_time_series.groupPerWeekday">groupPerWeekday</a></code></li>
<li><code><a title="analogistics.stat_time_series.poincare_section" href="#analogistics.stat_time_series.poincare_section">poincare_section</a></code></li>
<li><code><a title="analogistics.stat_time_series.returnSignificantLags" href="#analogistics.stat_time_series.returnSignificantLags">returnSignificantLags</a></code></li>
<li><code><a title="analogistics.stat_time_series.sampleTimeSeries" href="#analogistics.stat_time_series.sampleTimeSeries">sampleTimeSeries</a></code></li>
<li><code><a title="analogistics.stat_time_series.timeStampToDays" href="#analogistics.stat_time_series.timeStampToDays">timeStampToDays</a></code></li>
<li><code><a title="analogistics.stat_time_series.transformSeriesToStationary" href="#analogistics.stat_time_series.transformSeriesToStationary">transformSeriesToStationary</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>